[raypeat.rodeo](https://raypeat.rodeo) is the open-source effort to transcribe
the public works of Ray Peat.

[![Deploy to GitHub Pages](https://github.com/marcuswhybrow/ray-peat-rodeo/actions/workflows/gh-pages.yml/badge.svg)](https://github.com/marcuswhybrow/ray-peat-rodeo/actions/workflows/gh-pages.yml)
[![Built with Nix](https://builtwithnix.org/badge.svg)](https://builtwithnix.org)

![banner](https://raw.githubusercontent.com/marcuswhybrow/ray-peat-rodeo/back-to-go/internal/assets/docs/ray-peat-rodeo-banner.png)

# Getting Started

Get [Nix Package Manager](https://nixos.org/download.html#download-nix), then 
clone this repository and start the auto-reloading dev server:

```bash
git clone git@github.com:marcuswhybrow/ray-peat-rodeo.git
cd ray-peat-rodeo
nix develop -c modd
```

- `./assets` contains a markdown file for each article or transcription.
- `./assets/todo` contains a markdown file for assets without transcriptions.
- `./github/workflows/gh-pages` auto deploys this repo to https://raypeat.rodeo
- `./cmd/ray-peat-rodeo` is the code that builds the website from the markdown 
assets.
- `./cmd/whisper-json2md` is a custom tool to massage AI transcripts to 
markdown (see [here](#ai-transcription)).
- `./internal` contains this projects unique features, especially 
`./internal/markdown` and `./internal/cache/` which provide custom markdown 
plugins and automatic caching of remote data (e.g. GitHub issue titles).

Those are the main things, and editing any of them trigger the dev server to 
auto reload, and your browser should hot-load the changes and auto refresh, 
making a near instant dev cycle.

- `./flake.nix` & `./flake.lock` tell the `nix` command how to do everything 
for us, for example the dev server (lauched by `nix develop -c modd`), tells
nix to examine `./flake.nix` enter the custom shell environment defined 
there, and run the command `modd` which is our dev server of choice.
- `./gomod2nix.toml` in conjunction with `./flake.nix` helps the `nix` command 
build this project. It's autogenerated by running `nix develop -c gomod2nix`.
- `./modd.conf` tells `modd` how to behave, such as running Tailwind CCS 
process automatically.
- `./tailwind.config.js` tells tailwind how to do it's thing.

And finally, you may want to use `direnv` & `nix-direnv` to automatically load
all project dependencies and tools into your shell environment whilst you are 
inside the project directory (auto unloads when you leave it). In the root of 
the project directory:

```bash
cat "use flake" > .envrc
direnv allow
```

# Project Goals

1. Round up every Ray Peat interview, article, newsletter and book.
2. Use AI to quickly transcribe interviews.
3. Store each interview (etc.) as human readable markdown.
4. Generate an website from those markdown source files.
5. Site-wide search of all assets.
6. Tooltips for all mentioned topics and people linking to all other mentions.
7. Timestamps linking to specific times in original audio or video.
8. Sidenote annotations for clarifications and issues to be resolved.

What this amounts to is using AI to quickly transcribe all interviews, then 
storing the results in markdown. Next one improves and augments each markdown 
file with corrections, formatting and tagging all mentions and timecodes. 

Formatting is part of the markdown standard, but what I'm calling "mentions", 
"timecodes", and "issues" are extensions to the markdown syntax written 
specifically for this project. With custom markdown syntax any functionality
can be realised, whilst keeping the markdown documents human readible for 
archival purposed, and portability to other projects.


# AI Transcription

Perhaps a fully automated process will be forthcomming, but for now I'm 
manually running commands to transcribe audio files with AI, and copying the 
result by hand into existing markdown files inside of `./assets/todo/`. The 
following commands are all in the nix dev shell (which you can enter using 
`nix develop` if your not using direnv).

First I pick a file from ./assets/todo which doesn't have a transcript. Say,
the filename begins with the date 2022-02-02. Well, I copy the url from it's 
frontmatter key `source.url` and use `yt-dlp` to download the audio stream
and output the result to a file with that date as it's name:

```bash
yt-dlp -x "https://website.com/some-video-or-audio-file-url" -o 2022-02-02
```

Sometimes the output file will be called `2022-02-02.opus` or some other 
extension, sometimes it will have no extension. Let's assume it's `.opus`.

I then ask Whisper AI to transcribe the audio file and output a JSON file 
describing the results. I believe it's faster to tell Whisper it's and English 
language conversion:

```bash
whisper --language English --output_format json 2022-02-02.opus
```

This takes a while, and great while on old laptops. But once it's done you 
shoud have a file in the same directory called `2022-02-02.json`. I've chosen
JSON for it's flexibility in the next step.

The closest format whisper can output is `txt`. But this has no timestamp data 
in the output text. I'd like to pepper in timestamps (which whisper knows 
about) every minute or so into the resulting output. And I want them to adhere 
to out custom markdown extension: `[h:mm:ss]` e.g. `[1:23:45]`. The square 
brackets are important too.

So I call a custom tool written for this project that reads the JSON, ouputting
text in the way I've just descibed. I use linux redirection to append the that 
result to the end of the markdown file I started with:

```bash
whisper-json2md source-audio.json >> ./assets/todo/2022-02-02-example.md
```

Then I have a look at this markdown file, and check it out in the browser 
(which would be https://localhost:8000/example in this example).

Finally I update the frontmatter to reflect the new state of this asset.
I add the follow:

```yaml
transcription:
    date: 2024-04-10 # todays date
    author: Whisper AI 
    kind: auto-generated

added:
    date: 2024-04-10
    author: Marcus Whybrow # or your name instead
```

When the website is deployed this metadata makes sure everything looks right,
and the appropriate descriptions and details are available.
